{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Montvieux Ltd\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 16:17:39.072918: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 16:17:40.106368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "from IPython.display import display,clear_output,HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "import base64\n",
    "import json\n",
    "from io import StringIO\n",
    "import ipywidgets as widgets\n",
    "import sys\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from plark_game import classes\n",
    "from gym_plark.envs import plark_env,plark_env_guided_reward,plark_env_top_left,plark_env_sonobuoy_deployment, panther_env_reach_top\n",
    "\n",
    "\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "import helper \n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_plark.envs.plark_env:plark.kwargs :{'driving_agent': 'panther', 'render_height': 250, 'render_width': 310}\n",
      "INFO:gym_plark.envs.plark_env:self.image_based :True\n",
      "INFO:gym_plark.envs.plark_env:config filepath: /Components/plark-game/plark_game/game_config/10x10/balanced.json\n",
      "INFO:plark_game.classes.environment:Opening config from:/Components/plark-game/plark_game/game_config/10x10/balanced.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No configuration file provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/plark/plark_ai_public/Components/plark-game/plark_game/classes/environment.py:38\u001b[0m, in \u001b[0;36mEnvironment.load_game_configuration\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m     37\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mOpening config from:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(config_file))\n\u001b[0;32m---> 38\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(config_file) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     39\u001b[0m     game_config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Components/plark-game/plark_game/game_config/10x10/balanced.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[39m=\u001b[39m panther_env_reach_top\u001b[39m.\u001b[39;49mPantherEnvReachTop(config_file_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Components/plark-game/plark_game/game_config/10x10/balanced.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m check_env(env)\n",
      "File \u001b[0;32m~/plark/plark_ai_public/Components/gym-plark/gym_plark/envs/panther_env_reach_top.py:20\u001b[0m, in \u001b[0;36mPantherEnvReachTop.__init__\u001b[0;34m(self, config_file_path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \tkwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m     19\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mdriving_agent\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpanther\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[39msuper\u001b[39;49m(PantherEnvReachTop, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config_file_path,verbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriving_agent \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpanther\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     23\u001b[0m \t\u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis environment only supports panther\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/plark/plark_ai_public/Components/gym-plark/gym_plark/envs/plark_env.py:98\u001b[0m, in \u001b[0;36mPlarkEnv.__init__\u001b[0;34m(self, config_file_path, verbose, view_all, render_mode, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_index \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((val, key) \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mACTION_LOOKUP\u001b[39m.\u001b[39mitems())\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_based:\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mactiveGames[\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mactiveGames)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    100\u001b[0m     N_CHANNELS \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n",
      "File \u001b[0;32m~/plark/plark_ai_public/Components/gym-plark/gym_plark/envs/plark_env.py:252\u001b[0m, in \u001b[0;36mPlarkEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_file_path:\n\u001b[1;32m    251\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mconfig filepath: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_file_path))\n\u001b[0;32m--> 252\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mcreateNewGame(config_file_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_file_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mcreateNewGame(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\t\n",
      "File \u001b[0;32m~/plark/plark_ai_public/Components/plark-game/plark_game/classes/environment.py:17\u001b[0m, in \u001b[0;36mEnvironment.createNewGame\u001b[0;34m(self, config_file_path, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreateNewGame\u001b[39m(\u001b[39mself\u001b[39m, config_file_path\u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m config_file_path:\n\u001b[0;32m---> 17\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_game_configuration( config_file\u001b[39m=\u001b[39;49mconfig_file_path)\n\u001b[1;32m     18\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_game_configuration()\n",
      "File \u001b[0;32m~/plark/plark_ai_public/Components/plark-game/plark_game/classes/environment.py:42\u001b[0m, in \u001b[0;36mEnvironment.load_game_configuration\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[39mreturn\u001b[39;00m game_config\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo configuration file provided\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No configuration file provided"
     ]
    }
   ],
   "source": [
    "env = panther_env_reach_top.PantherEnvReachTop(config_file_path='/Components/plark-game/plark_game/game_config/10x10/balanced.json')\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_eval_episodes = 10\n",
    "training_steps = 200\n",
    "\n",
    "#env.driving_agent = 'panther'\n",
    "\n",
    "model = PPO('CnnPolicy', env)\n",
    "#model = PPO('CnnPolicy', 'plark-v0') \n",
    "#model = A2C('CnnPolicy', env)\n",
    "model.learn(training_steps)\n",
    "\n",
    "print(\"****** STARTING EVALUATION *******\")\n",
    "mean_reward, n_steps = evaluate_policy(model, env, n_eval_episodes=n_eval_episodes, deterministic=False, render=False, callback=None, reward_threshold=None, return_episode_rewards=False)\n",
    "print(\"****** EVALUATION FINISHED *******\")\n",
    "print(\"Mean Reward is \" + str(mean_reward))\n",
    "print(\"Number of steps is \" + str(n_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model \n",
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "modeltype = 'PPO'\n",
    "modelplayer = env.driving_agent \n",
    "render_height = env.render_height\n",
    "render_width = env.render_width\n",
    "image_based = True\n",
    "helper.save_model(exp_path,model,modeltype,modelplayer,render_height,render_width,image_based,basicdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/test.mp4'\n",
    "basewidth,hsize = helper.make_video(model,env,video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open(video_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
