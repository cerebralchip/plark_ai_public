{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Montvieux Ltd\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from IPython.display import display,clear_output,HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "import base64\n",
    "import json\n",
    "from io import StringIO\n",
    "import ipywidgets as widgets\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import imageio\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from plark_game import classes\n",
    "from gym_plark.envs import plark_env,plark_env_guided_reward,plark_env_top_left\n",
    "\n",
    "\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "import helper \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/agents/models/test_20230426_095040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the self play training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/agents/models/test_20230426_095043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 09:50:45.679800: I tensorflow/stream_executor/platform/default/dso_loader.cc:50] Successfully opened dynamic library libcudart.so.12\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "INFO:gym_plark.envs.plark_env:plark.kwargs :{'driving_agent': 'pelican', 'image_based': True, 'random_panther_start_position': True, 'max_illegal_moves_per_turn': 5, 'render_height': 250, 'render_width': 310}\n",
      "INFO:gym_plark.envs.plark_env:self.image_based :True\n",
      "INFO:gym_plark.envs.plark_env:config filepath: /Components/plark-game/plark_game/game_config/10x10/pelican_easy.json\n",
      "INFO:plark_game.classes.environment:Opening config from:/Components/plark-game/plark_game/game_config/10x10/pelican_easy.json\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_3_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_5_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_move_north.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/__init__.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_any_size_grid.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_random_walk.py\n",
      "INFO:plark_game.classes.newgame:kwargs: {'driving_agent': 'pelican', 'image_based': True, 'random_panther_start_position': True, 'max_illegal_moves_per_turn': 5, 'render_height': 250, 'render_width': 310}\n",
      "INFO:plark_game.classes.newgame:Playing against:Panther_Agent_Move_North\n",
      "INFO:plark_game.classes.environment:Game Created\n",
      "INFO:gym_plark.envs.plark_env:observation space: Height:250, Width:310, Channels:3\n",
      "INFO:gym_plark.envs.plark_env:Image observations created\n",
      "INFO:self_play:Training initial pelican\n",
      "INFO:self_play:Beginning training for 1 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican/PPO_20230426_095043_pelican.zip\n",
      "DEBUG:helper:Evaluating policy\n",
      "DEBUG:helper:Evaluating episode 0 of 10\n",
      "DEBUG:helper:Evaluating episode 1 of 10\n",
      "DEBUG:helper:Evaluating episode 2 of 10\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "DEBUG:helper:Evaluating episode 3 of 10\n",
      "DEBUG:helper:Evaluating episode 4 of 10\n",
      "DEBUG:helper:Evaluating episode 5 of 10\n",
      "DEBUG:helper:Evaluating episode 6 of 10\n",
      "DEBUG:helper:Evaluating episode 7 of 10\n",
      "DEBUG:helper:Evaluating episode 8 of 10\n",
      "DEBUG:helper:Evaluating episode 9 of 10\n",
      "INFO:helper:victory_count = 2\n",
      "INFO:helper:avg_reward = -0.71\n",
      "INFO:self_play:steps = 100\n",
      "INFO:helper:Checking folder: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican/PPO_20230426_095043_pelican.zip\n",
      "2023-04-26 09:57:47.942571: I tensorflow/stream_executor/platform/default/dso_loader.cc:50] Successfully opened dynamic library libcudart.so.12\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "INFO:gym_plark.envs.plark_env:plark.kwargs :{'driving_agent': 'panther', 'pelican_agent_filepath': '/data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican', 'image_based': True, 'random_panther_start_position': True, 'max_illegal_moves_per_turn': 5, 'render_height': 250, 'render_width': 310}\n",
      "INFO:gym_plark.envs.plark_env:self.image_based :True\n",
      "INFO:gym_plark.envs.plark_env:config filepath: /Components/plark-game/plark_game/game_config/10x10/balanced.json\n",
      "INFO:plark_game.classes.environment:Opening config from:/Components/plark-game/plark_game/game_config/10x10/balanced.json\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_3_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_5_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_move_north.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/__init__.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_any_size_grid.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_random_walk.py\n",
      "INFO:plark_game.classes.newgame:kwargs: {'driving_agent': 'panther', 'pelican_agent_filepath': '/data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican', 'image_based': True, 'random_panther_start_position': True, 'max_illegal_moves_per_turn': 5, 'render_height': 250, 'render_width': 310}\n",
      "INFO:plark_game.classes.newgame:Playing against:/data/agents/models/test_20230426_095043/PPO_20230426_095043_pelican/PPO_20230426_095043_pelican.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plark_game.classes.pelicanAgent_load_agent:pelican agent loaded\n",
      "INFO:plark_game.classes.environment:Game Created\n",
      "INFO:gym_plark.envs.plark_env:observation space: Height:250, Width:310, Channels:3\n",
      "INFO:gym_plark.envs.plark_env:Image observations created\n",
      "INFO:self_play:Training initial panther\n",
      "INFO:self_play:Beginning training for 1 steps\n",
      "INFO:self_play:Training for 100 steps\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending panther turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending panther turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending panther turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending panther turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (5). Ending pelican turn...\n",
      "Process ForkServerProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 34, in _worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Process ForkServerProcess-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 34, in _worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(exp_path)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# video_path,basewidth,hsize = self_play.run_self_play(exp_name,exp_path,basicdate,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#                     pelican_testing_interval=1000,pelican_max_initial_learning_steps=10000,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#                     panther_testing_interval=1000,panther_max_initial_learning_steps=10000,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#                     self_play_testing_interval=1000,self_play_max_learning_steps_per_agent=10000,self_play_iterations=10,\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#                     model_type='dqn',log_to_tb=True                                 \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#                 )\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m video_path,basewidth,hsize \u001b[38;5;241m=\u001b[39m \u001b[43mself_play\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_self_play\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbasicdate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpelican_testing_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpelican_max_initial_learning_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpanther_testing_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpanther_max_initial_learning_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mself_play_testing_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mself_play_max_learning_steps_per_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mself_play_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlog_to_tb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m                                 \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Components/agent-training/agent_training/self_play.py:115\u001b[0m, in \u001b[0;36mrun_self_play\u001b[0;34m(exp_name, exp_path, basicdate, pelican_testing_interval, pelican_max_initial_learning_steps, panther_testing_interval, panther_max_initial_learning_steps, self_play_testing_interval, self_play_max_learning_steps_per_agent, self_play_iterations, model_type, log_to_tb, image_based, num_parallel_envs)\u001b[0m\n\u001b[1;32m    113\u001b[0m panther_model \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39mmake_new_model(model_type,policy, panther_env)        \n\u001b[1;32m    114\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining initial panther\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m panther_agent_filepath, steps \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpanther_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpanther_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpanther_testing_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpanther_max_initial_learning_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpanther_model_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbasicdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpanther_tb_log_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m panther_training_steps \u001b[38;5;241m=\u001b[39m panther_training_steps \u001b[38;5;241m+\u001b[39m steps\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Train agent vs agent\u001b[39;00m\n",
      "File \u001b[0;32m/Components/agent-training/agent_training/self_play.py:47\u001b[0m, in \u001b[0;36mtrain_agent\u001b[0;34m(exp_path, model, env, testing_interval, max_steps, model_type, basicdate, tb_writer, tb_log_name, early_stopping, previous_steps)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m max_steps:\n\u001b[1;32m     46\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m steps\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(testing_interval))\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_interval\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     48\u001b[0m     steps \u001b[38;5;241m=\u001b[39m steps \u001b[38;5;241m+\u001b[39m testing_interval\n\u001b[1;32m     49\u001b[0m     agent_filepath,_,_\u001b[38;5;241m=\u001b[39m   helper\u001b[38;5;241m.\u001b[39msave_model_with_env_settings(exp_path,model,model_type,env,basicdate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/on_policy_algorithm.py:281\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime/total_timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdump(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps)\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:275\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 393\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import self_play\n",
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)\n",
    "# video_path,basewidth,hsize = self_play.run_self_play(exp_name,exp_path,basicdate,\n",
    "#                     pelican_testing_interval=1000,pelican_max_initial_learning_steps=10000,\n",
    "#                     panther_testing_interval=1000,panther_max_initial_learning_steps=10000,\n",
    "#                     self_play_testing_interval=1000,self_play_max_learning_steps_per_agent=10000,self_play_iterations=10,\n",
    "#                     model_type='dqn',log_to_tb=True                                 \n",
    "#                 )\n",
    "\n",
    "video_path,basewidth,hsize = self_play.run_self_play(exp_name,exp_path,basicdate,\n",
    "                    pelican_testing_interval=100,pelican_max_initial_learning_steps=1,\n",
    "                    panther_testing_interval=100,panther_max_initial_learning_steps=1,\n",
    "                    self_play_testing_interval=100,self_play_max_learning_steps_per_agent=1,self_play_iterations=1,\n",
    "                    model_type='PPO',log_to_tb=False                                 \n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = '/data/agents/models/test_20200325_184254/test_self_play.mp4'\n",
    "# basewidth = 310\n",
    "# hsize = 250\n",
    "video = io.open(video_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make video of previously trained agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update the paths below.\n",
    "panther_agent_filepath = '/data/agents/models/test_20200409_160900/PPO2_20200409_160900_panther/'\n",
    "pelican_env = plark_env.PlarkEnv(driving_agent='pelican',panther_agent_filepath=panther_agent_filepath,config_file_path='/Components/plark-game/plark_game/game_config/10x10/balanced.json')\n",
    "pelican_load_path = '/data/agents/models/test_20200409_160900/PPO2_20200409_160900_pelican/PPO2_20200409_160900_pelican.zip'\n",
    "pelican_model = PPO2.load(pelican_load_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/data/test_video/'\n",
    "os.makedirs(video_path, exist_ok=True)\n",
    "video_file_path =  os.path.join(video_path, 'test_self_play.mp4') \n",
    "basewidth,hsize = helper.make_video(pelican_model,pelican_env,video_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open(video_file_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
