{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Montvieux Ltd\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:03:55.284058: I tensorflow/stream_executor/platform/default/dso_loader.cc:50] Successfully opened dynamic library libcudart.so.12\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "from IPython.display import display,clear_output,HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "import base64\n",
    "import json\n",
    "from io import StringIO\n",
    "import ipywidgets as widgets\n",
    "import sys\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from plark_game import classes\n",
    "from gym_plark.envs import plark_env,plark_env_guided_reward,plark_env_top_left\n",
    "\n",
    "\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "import helper \n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_plark.envs.plark_env:plark.kwargs :{'render_height': 250, 'render_width': 310, 'driving_agent': 'pelican'}\n",
      "INFO:gym_plark.envs.plark_env:self.image_based :True\n",
      "INFO:plark_game.classes.environment:Opening config from:/Components/plark-game/plark_game/game_config/10x10/balanced.json\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_3_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_5_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_move_north.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/__init__.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_any_size_grid.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_random_walk.py\n",
      "INFO:plark_game.classes.newgame:kwargs: {'render_height': 250, 'render_width': 310, 'driving_agent': 'pelican'}\n",
      "INFO:plark_game.classes.newgame:Playing against:Panther_Agent_Random_Walk\n",
      "INFO:plark_game.classes.environment:Game Created\n",
      "INFO:gym_plark.envs.plark_env:observation space: Height:250, Width:310, Channels:3\n",
      "INFO:gym_plark.envs.plark_env:Image observations created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = plark_env.PlarkEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = plark_env_guided_reward.PlarkEnvGuidedReward()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_plark.envs.plark_env:plark.kwargs :{'driving_agent': 'pelican', 'render_height': 250, 'render_width': 310}\n",
      "INFO:gym_plark.envs.plark_env:self.image_based :True\n",
      "INFO:plark_game.classes.environment:Opening config from:/Components/plark-game/plark_game/game_config/10x10/balanced.json\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_3_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_5_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_move_north.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/__init__.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_any_size_grid.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_random_walk.py\n",
      "INFO:plark_game.classes.newgame:kwargs: {'driving_agent': 'pelican', 'render_height': 250, 'render_width': 310}\n",
      "INFO:plark_game.classes.newgame:Playing against:Panther_Agent_Random_Walk\n",
      "INFO:plark_game.classes.environment:Game Created\n",
      "INFO:gym_plark.envs.plark_env:observation space: Height:250, Width:310, Channels:3\n",
      "INFO:gym_plark.envs.plark_env:Image observations created\n"
     ]
    }
   ],
   "source": [
    "env = plark_env_top_left.PlarkEnvTopLeft()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_plark.envs.plark_env:plark.kwargs :{'render_height': 250, 'render_width': 310, 'driving_agent': 'pelican'}\n",
      "INFO:gym_plark.envs.plark_env:self.image_based :True\n",
      "INFO:gym_plark.envs.plark_env:config filepath: /Components/plark-game/plark_game/game_config/30x30/balanced.json\n",
      "INFO:plark_game.classes.environment:Opening config from:/Components/plark-game/plark_game/game_config/30x30/balanced.json\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_3_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_5_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_move_north.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/__init__.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_any_size_grid.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_random_walk.py\n",
      "INFO:plark_game.classes.newgame:kwargs: {'render_height': 250, 'render_width': 310, 'driving_agent': 'pelican'}\n",
      "INFO:plark_game.classes.newgame:Playing against:Panther_Agent_Random_Walk\n",
      "INFO:plark_game.classes.environment:Game Created\n",
      "INFO:gym_plark.envs.plark_env:observation space: Height:250, Width:310, Channels:3\n",
      "INFO:gym_plark.envs.plark_env:Image observations created\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (10). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (10). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (10). Ending pelican turn...\n",
      "WARNING:plark_game.classes.newgame:Too many illegal moves (10). Ending pelican turn...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** STARTING EVALUATION *******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** EVALUATION FINISHED *******\n",
      "Mean Reward is -0.8000000156462193\n",
      "Number of steps is 1.000000011175871\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define and Train the agent\n",
    "#model = A2C('CnnPolicy', env).learn(total_timesteps=1000)\n",
    "\n",
    "# Instantiate the env\n",
    "env = plark_env.PlarkEnv(config_file_path='/Components/plark-game/plark_game/game_config/30x30/balanced.json')\n",
    "\n",
    "n_eval_episodes = 2\n",
    "training_steps = 10\n",
    "\n",
    "model = PPO('CnnPolicy', env)\n",
    "#model = PPO2('CnnPolicy', 'plark-v0') \n",
    "#model = A2C('CnnPolicy', env)\n",
    "model.learn(training_steps)\n",
    "\n",
    "print(\"****** STARTING EVALUATION *******\")\n",
    "mean_reward, n_steps = evaluate_policy(model, env, n_eval_episodes=n_eval_episodes, deterministic=False, render=False, callback=None, reward_threshold=None, return_episode_rewards=False)\n",
    "print(\"****** EVALUATION FINISHED *******\")\n",
    "print(\"Mean Reward is \" + str(mean_reward))\n",
    "print(\"Number of steps is \" + str(n_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/agents/models/test_20230426_111042\n"
     ]
    }
   ],
   "source": [
    "#Save model \n",
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper:Checking folder: /data/agents/models/test_20230426_111042/PPO_20230426_111046_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20230426_111042/PPO_20230426_111046_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20230426_111042/PPO_20230426_111046_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20230426_111042/PPO_20230426_111046_pelican/PPO_20230426_111046_pelican.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/data/agents/models/test_20230426_111042/PPO_20230426_111046_pelican/PPO_20230426_111046_pelican.zip',\n",
       " '/data/agents/models/test_20230426_111042/PPO_20230426_111046_pelican',\n",
       " 'PPO_20230426_111046_pelican')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "modeltype = 'PPO'\n",
    "modelplayer = env.driving_agent \n",
    "render_height = env.render_height\n",
    "render_width = env.render_width\n",
    "\n",
    "helper.save_model(exp_path,model,modeltype,modelplayer,render_height,render_width,basicdate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper:Checking folder: /data/agents/models/test_20230426_111042/PPO_20230426_111042_pelican\n",
      "INFO:helper:Saving Metadata\n",
      "INFO:helper:json saved to: /data/agents/models/test_20230426_111042/PPO_20230426_111042_pelican/metadata.json\n",
      "INFO:helper:Saving Model\n",
      "INFO:helper:model_dir: /data/agents/models/test_20230426_111042/PPO_20230426_111042_pelican\n",
      "INFO:helper:model_path: /data/agents/models/test_20230426_111042/PPO_20230426_111042_pelican/PPO_20230426_111042_pelican.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/data/agents/models/test_20230426_111042/PPO_20230426_111042_pelican/PPO_20230426_111042_pelican.zip',\n",
       " '/data/agents/models/test_20230426_111042/PPO_20230426_111042_pelican',\n",
       " 'PPO_20230426_111042_pelican')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "helper.save_model_with_env_settings(exp_path,model,modeltype,env,basicdate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/test.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m basewidth,hsize \u001b[38;5;241m=\u001b[39m \u001b[43mhelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Components/agent-training/agent_training/helper.py:343\u001b[0m, in \u001b[0;36mmake_video\u001b[0;34m(model, env, video_file_path, n_steps, fps, deterministic, basewidth, verbose)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps):\n\u001b[1;32m    342\u001b[0m     image \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender(view\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 343\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/base_class.py:555\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    537\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    541\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/policies.py:346\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# Switch to eval mode (this affects batch norm / dropout)\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_training_mode(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 346\u001b[0m observation, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    349\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(observation, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/policies.py:257\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    252\u001b[0m         observation[key] \u001b[38;5;241m=\u001b[39m obs_\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space[key]\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_image_space(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Handle the different cases for images\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# as PyTorch use channel first format\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     observation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(observation)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/preprocessing.py:84\u001b[0m, in \u001b[0;36mmaybe_transpose\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VecTransposeImage\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_image_space(observation_space):\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mobservation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mor\u001b[39;00m observation\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m# Try to re-order the channels\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         transpose_obs \u001b[38;5;241m=\u001b[39m VecTransposeImage\u001b[38;5;241m.\u001b[39mtranspose_image(observation)\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m transpose_obs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mor\u001b[39;00m transpose_obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "video_path = '/test.mp4'\n",
    "basewidth,hsize = helper.make_video(model,env,video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/test.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr+b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      2\u001b[0m encoded \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(video)\n\u001b[1;32m      3\u001b[0m HTML(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m<video alt=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(basewidth)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m height=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(hsize)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m controls>\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m                <source src=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:video/mp4;base64,\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m type=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo/mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m />\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m             </video>\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;241m.\u001b[39mformat(encoded\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/test.mp4'"
     ]
    }
   ],
   "source": [
    "video = io.open(video_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
